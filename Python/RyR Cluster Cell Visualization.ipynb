{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de0fd03-bf50-4fcc-9531-dbcbf2d434b7",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276120e9-51d2-449d-9c55-7ec32fb18ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62eb0e-9555-4471-b4d0-e817e258480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(root, pattern):\n",
    "    \"\"\"Recursively find files matching the given pattern in directory and sub-directories.\"\"\"\n",
    "    matched_files = []\n",
    "    for root, dirs, files in os.walk(root):\n",
    "        for file in files:\n",
    "            if pattern in file:\n",
    "                matched_files.append(os.path.join(root, file))\n",
    "    return matched_files\n",
    "\n",
    "def extract_file_type(filename):\n",
    "    \"\"\"Extract the specific file type from the filename, handling complex names.\"\"\"\n",
    "    parts = filename.split('_')\n",
    "    type_part = parts[-1].split('.')[0]\n",
    "    return type_part\n",
    "\n",
    "def collect_files(root, filter_dir):\n",
    "    \"\"\"Collect specific files and organize them into a DataFrame, filtered by matching .jpg files in a directory.\"\"\"\n",
    "    # Collect all .jpg files in the filter directory\n",
    "    filter_files = {os.path.basename(f): f for f in get_files(filter_dir, '.jpg')}\n",
    "    print(f\"Filtering with .jpg files found in {filter_dir}: {len(filter_files)} files\")\n",
    "\n",
    "    rows = []\n",
    "    # Walk through each subdirectory and check for matching .jpg file presence\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        # Skip the filter_dir (CELLS_TO_USE directory) while processing subdirectories\n",
    "        if os.path.abspath(subdir) == os.path.abspath(filter_dir):\n",
    "            continue\n",
    "\n",
    "        sub_jpgs = [f for f in files if f.endswith('.jpg')]\n",
    "        if any(jpg in filter_files for jpg in sub_jpgs):  # Process subdirectory if matching .jpg is found\n",
    "            file_dict = {}\n",
    "            for file in files:\n",
    "                filetype = extract_file_type(file)\n",
    "                if filetype in ['adjmatrix', 'alphashape', 'centroids', 'clusterlabels', \n",
    "                                'filteredvolume', 'neighboralphacentroid', 'surfacearea', \n",
    "                                'volume', 'volumes', 'voxellist']:\n",
    "                    file_dict[filetype] = os.path.join(subdir, file)\n",
    "            if file_dict:\n",
    "                rows.append(file_dict)\n",
    "\n",
    "    # Create DataFrame\n",
    "    dataframe = pd.DataFrame(rows)\n",
    "    if dataframe.empty:\n",
    "        print(\"No data collected. DataFrame is empty.\")\n",
    "    else:\n",
    "        print(\"DataFrame created successfully.\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049aa4b-edb5-450b-9c45-edcc915b44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = r'E:\\RABBIT_DATA\\NEW_AI_RESULTS_V11\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872d700-fb06-402c-9a03-914fef858b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dir = os.path.join(DATA_ROOT, 'CELLS_TO_USE')\n",
    "df_input = collect_files(DATA_ROOT, filter_dir)\n",
    "DATA_TO_USE = df_input[['adjmatrix', 'volumes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc252380-51dc-4142-b8f5-800d4c17f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DATA_TO_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbb815-a959-4892-a019-a9422a368936",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_x = 55.5\n",
    "vox_y = 55.5\n",
    "vox_z = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec10ca5-7f28-4074-a0c1-0f1d8b896b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_x = 100\n",
    "vox_y = 100\n",
    "vox_z = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23d8f9-688c-47aa-a9f1-d8707b2d151c",
   "metadata": {},
   "source": [
    "### Plotly HTML RyR Cluster Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6a514-96ec-4046-81c6-d0195c971ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define DataFrame to collect results\n",
    "df_results = pd.DataFrame(columns=['Cell Number', 'I', 'Volume', 'Surface Area'])\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for idx, row in DATA_TO_USE.iterrows():\n",
    "    adj_matrix_file = row['adjmatrix']\n",
    "    centroid_file = row['volumes']\n",
    "    cell_name = os.path.basename(centroid_file).split('_')[:-1]\n",
    "    cell_name = '_'.join(cell_name)\n",
    "    print(cell_name)\n",
    "\n",
    "    # Read the volumes file which contains centroids with volumes\n",
    "    df_raw = pd.read_csv(centroid_file, header=None, names=['x', 'y', 'z', 'volume'])\n",
    "    df_raw['z'] = df_raw['z']\n",
    "\n",
    "    # Append coordinates and volumes to lists\n",
    "    all_coords = df_raw[['x', 'y', 'z']].values\n",
    "    all_volumes = df_raw['volume'].values\n",
    "\n",
    "    # Read and process the adjacency matrix\n",
    "    A = np.genfromtxt(adj_matrix_file, delimiter=',')\n",
    "    G = nx.from_numpy_array(A)\n",
    "\n",
    "    print(f\"Processed adjacency matrix for {os.path.basename(adj_matrix_file)}, number of nodes: {G.number_of_nodes()}, edges: {G.number_of_edges()}\")\n",
    "    # Convert lists to numpy arrays for graph processing\n",
    "    all_coords = np.array(all_coords)\n",
    "    all_volumes = np.array(all_volumes)\n",
    "    \n",
    "    # Normalize volumes for color mapping and calculate log10 for size scaling\n",
    "    normalized_volumes = (all_volumes - np.min(all_volumes)) / (np.max(all_volumes) - np.min(all_volumes))\n",
    "    #sizes = np.log10(all_volumes) * 3  # Scale log of volumes by a factor for visibility\n",
    "    #sizes = all_volumes * (1/1000)\n",
    "    sizes = 25 * ((all_volumes - np.min(all_volumes)) / (np.max(all_volumes) - np.min(all_volumes)))\n",
    "\n",
    "    # Create a graph using an adjacency matrix\n",
    "    adj_matrix = np.genfromtxt(adj_matrix_file, delimiter=',')\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    \n",
    "    # Create edge traces\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_z = []\n",
    "    \n",
    "    for edge in G.edges():\n",
    "        x0, y0, z0 = all_coords[edge[0]]\n",
    "        x1, y1, z1 = all_coords[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_z.extend([z0, z1, None])\n",
    "    \n",
    "    trace_edges = go.Scatter3d(x=edge_x, y=edge_y, z=edge_z, mode='lines',\n",
    "                               line=dict(color='black', width=0.5), hoverinfo='none')\n",
    "    \n",
    "    # Create node traces with size and color scaling\n",
    "    trace_nodes = go.Scatter3d(\n",
    "        x=all_coords[:, 0], y=all_coords[:, 1], z=all_coords[:, 2], mode='markers',\n",
    "        marker=dict(\n",
    "            size=sizes,\n",
    "            color=normalized_volumes,  # Use normalized volumes for coloring\n",
    "            colorscale='Viridis',  # Color scale\n",
    "            colorbar=dict(title='Node Volumes'),\n",
    "            line=dict(color='black', width=0.5)\n",
    "        ),\n",
    "        opacity=0.75,\n",
    "        text=[f'Node {i}, Volume: {vol:.2f}' for i, vol in enumerate(all_volumes)],\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "    \n",
    "    # Set layout\n",
    "    #we need to set the axis for the plot \n",
    "    axis = dict(showbackground=False,\n",
    "                showline=False,\n",
    "                zeroline=False,\n",
    "                showgrid=False,\n",
    "                showticklabels=False,\n",
    "                title='')\n",
    "    \n",
    "    #also need to create the layout for our plot\n",
    "    layout = go.Layout(title=f\"{cell_name} Periphery RyR Clusters\",\n",
    "                    width=1650,\n",
    "                    height=1650,\n",
    "                    showlegend=False,\n",
    "                    scene=dict(xaxis=dict(axis),\n",
    "                            yaxis=dict(axis),\n",
    "                            zaxis=dict(axis),\n",
    "                            aspectmode='data'\n",
    "                            ),\n",
    "                    margin=dict(t=100),\n",
    "                    hovermode='closest')\n",
    "    \n",
    "    # Define the figure\n",
    "    fig = go.Figure(data=[trace_edges, trace_nodes], layout=layout)\n",
    "    export_html_name = f'{cell_name}-3dviz.html'\n",
    "    fig.write_html(export_html_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb0074-34a3-43cf-9afd-096b8cce17eb",
   "metadata": {},
   "source": [
    "## GLB RyR Cluster Netork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ac495-273f-4ce9-825c-d502e1b03721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import trimesh\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import colormaps  # Updated import for colormaps\n",
    "\n",
    "# User-defined parameters for adjusting sizes\n",
    "NODE_SIZE_FACTOR = 750       # Adjust this value to control the overall node sizes\n",
    "MIN_NODE_SIZE = 1.0         # Minimum node size to ensure visibility\n",
    "EDGE_THICKNESS = 10.0       # Adjust this value to control the edge (line) thickness\n",
    "SPHERE_SUBDIVISIONS = 1     # Controls the detail level of spheres (nodes)\n",
    "CYLINDER_SECTIONS = 4  # Controls the detail level of cylinders (edges)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for idx, row in DATA_TO_USE.iterrows():\n",
    "    adj_matrix_file = row['adjmatrix']\n",
    "    centroid_file = row['volumes']\n",
    "    cell_name = os.path.basename(centroid_file).split('_')[:-1]\n",
    "    cell_name = '_'.join(cell_name)\n",
    "    print(cell_name)\n",
    "\n",
    "    # Read the volumes file\n",
    "    df_raw = pd.read_csv(centroid_file, header=None, names=['x', 'y', 'z', 'volume'])\n",
    "    df_raw['z'] = df_raw['z']\n",
    "\n",
    "    # Extract coordinates and volumes\n",
    "    all_coords = df_raw[['x', 'y', 'z']].values\n",
    "    all_volumes = df_raw['volume'].values\n",
    "\n",
    "    # Read and process the adjacency matrix\n",
    "    A = np.genfromtxt(adj_matrix_file, delimiter=',')\n",
    "    G = nx.from_numpy_array(A)\n",
    "\n",
    "    print(f\"Processed adjacency matrix for {os.path.basename(adj_matrix_file)}, number of nodes: {G.number_of_nodes()}, edges: {G.number_of_edges()}\")\n",
    "\n",
    "    # Normalize volumes to range between 0 and 1\n",
    "    normalized_volumes = (all_volumes - np.min(all_volumes)) / (np.max(all_volumes) - np.min(all_volumes))\n",
    "\n",
    "    # Calculate sizes with adjustable scaling factor\n",
    "    sizes = NODE_SIZE_FACTOR * normalized_volumes\n",
    "    sizes = np.clip(sizes, MIN_NODE_SIZE, None)  # Ensure sizes are not too small\n",
    "\n",
    "    # Map normalized volumes to colors\n",
    "    cmap = cc.cm['linear_kbgoy_20_95_c57']  # Updated as per your request\n",
    "    norm = colors.Normalize(vmin=0, vmax=1)\n",
    "    mapped_colors = cmap(norm(normalized_volumes))  # RGBA colors\n",
    "\n",
    "    # Convert colors to uint8\n",
    "    vertex_colors = (mapped_colors[:, :3] * 255).astype(np.uint8)\n",
    "\n",
    "    # List to hold all geometries\n",
    "    geometries = []\n",
    "\n",
    "    # Create sphere meshes for nodes\n",
    "    for i in range(len(all_coords)):\n",
    "        position = all_coords[i]\n",
    "        radius = sizes[i]\n",
    "        color = vertex_colors[i]\n",
    "\n",
    "        # Create a sphere with adjustable subdivisions\n",
    "        sphere = trimesh.creation.icosphere(subdivisions=SPHERE_SUBDIVISIONS, radius=radius)\n",
    "        sphere.apply_translation(position)\n",
    "\n",
    "        # Assign color to the sphere's vertices\n",
    "        sphere.visual.vertex_colors = np.tile(color, (sphere.vertices.shape[0], 1))\n",
    "\n",
    "        geometries.append(sphere)\n",
    "\n",
    "    # Create cylinder meshes for edges\n",
    "    for edge in G.edges():\n",
    "        start = all_coords[edge[0]]\n",
    "        end = all_coords[edge[1]]\n",
    "\n",
    "        # Compute vector from start to end\n",
    "        vector = end - start\n",
    "        length = np.linalg.norm(vector)\n",
    "        if length == 0:\n",
    "            continue  # Skip zero-length edges\n",
    "        direction = vector / length\n",
    "\n",
    "        # Create a cylinder with adjustable thickness and sections\n",
    "        cylinder = trimesh.creation.cylinder(\n",
    "            radius=EDGE_THICKNESS,\n",
    "            height=length,\n",
    "            sections=CYLINDER_SECTIONS\n",
    "        )\n",
    "        # Align the cylinder with the edge vector\n",
    "        cylinder.apply_translation([0, 0, length / 2])\n",
    "        axis = [0, 0, 1]\n",
    "        rotation_matrix = trimesh.geometry.align_vectors(axis, direction)\n",
    "        cylinder.apply_transform(rotation_matrix)\n",
    "        # Move the cylinder to the start position\n",
    "        cylinder.apply_translation(start)\n",
    "\n",
    "        # Assign color to the cylinder (e.g., black)\n",
    "        cylinder_color = np.array([0, 0, 0], dtype=np.uint8)\n",
    "        cylinder.visual.vertex_colors = np.tile(cylinder_color, (cylinder.vertices.shape[0], 1))\n",
    "\n",
    "        geometries.append(cylinder)\n",
    "\n",
    "    # Combine all geometries into a single mesh\n",
    "    combined = trimesh.util.concatenate(geometries)\n",
    "\n",
    "    # Clean up the mesh\n",
    "    combined.remove_duplicate_faces()\n",
    "    combined.remove_unreferenced_vertices()\n",
    "\n",
    "    # Export to GLB file\n",
    "    export_glb_name = f'{cell_name}-3dviz-clusters.glb'\n",
    "    combined.export(export_glb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b2fd4-a6d2-4889-b457-8e00d81939eb",
   "metadata": {},
   "source": [
    "## Denisty Mesh Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01060002-8310-4c86-b376-318157e94349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import trimesh\n",
    "import os\n",
    "from scipy.spatial import cKDTree\n",
    "from matplotlib import cm\n",
    "\n",
    "# Parameters for visualization\n",
    "SHOW_FACES = True             # Set to True to show mesh faces, False to hide\n",
    "\n",
    "# Parameters for scaling node sizes and edge thicknesses\n",
    "NODE_SIZE_SCALE = 0.0025        # Scale factor for node sizes (as a fraction of model size)\n",
    "EDGE_THICKNESS_SCALE = 0.00025  # Scale factor for edge thickness (as a fraction of model size)\n",
    "\n",
    "SPHERE_SUBDIVISIONS = 1      # Controls the detail level of spheres (nodes)\n",
    "CYLINDER_SECTIONS = 4         # Controls the detail level of cylinders (edges)\n",
    "\n",
    "# Flag to flip colors\n",
    "FLIP_COLORS = False           # Set to True to flip the colors, False to keep original mapping\n",
    "\n",
    "def create_faces_from_adjacency(A):\n",
    "    G = nx.from_numpy_array(A)\n",
    "    triangles = []\n",
    "    for node in G.nodes():\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        for i in range(len(neighbors)):\n",
    "            for j in range(i+1, len(neighbors)):\n",
    "                if G.has_edge(neighbors[i], neighbors[j]):\n",
    "                    triangles.append([node, neighbors[i], neighbors[j]])\n",
    "    return np.array(triangles)\n",
    "    \n",
    "# Iterate through each row in the DataFrame\n",
    "for idx, row in DATA_TO_USE.iterrows():\n",
    "    adj_matrix_file = row['adjmatrix']\n",
    "    centroid_file = row['volumes']\n",
    "    cell_name = os.path.basename(centroid_file).split('_')[:-1]\n",
    "    cell_name = '_'.join(cell_name)\n",
    "\n",
    "    # Read the volumes file\n",
    "    df_raw = pd.read_csv(centroid_file, header=None, names=['x', 'y', 'z', 'volume'])\n",
    "    vertices = df_raw[['x', 'y', 'z']].values\n",
    "    node_sizes = df_raw['volume'].values\n",
    "\n",
    "    # Read and process the adjacency matrix\n",
    "    A = np.genfromtxt(adj_matrix_file, delimiter=',')\n",
    "    G = nx.from_numpy_array(A)\n",
    "\n",
    "    # Create faces from the adjacency matrix\n",
    "    faces = create_faces_from_adjacency(A)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        continue  # Skip this iteration if no faces can be formed\n",
    "\n",
    "    try:\n",
    "        # Create mesh from vertices and faces\n",
    "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, process=False)\n",
    "\n",
    "        # Process the mesh\n",
    "        mesh.process()\n",
    "\n",
    "        # Compute average edge length for SIGMA\n",
    "        edge_lengths = []\n",
    "        for edge in G.edges():\n",
    "            i, j = edge\n",
    "            x_i = vertices[i]\n",
    "            x_j = vertices[j]\n",
    "            length = np.linalg.norm(x_i - x_j)\n",
    "            edge_lengths.append(length)\n",
    "        avg_edge_length = np.mean(edge_lengths)\n",
    "        SIGMA = avg_edge_length / 4  # Adjust as needed\n",
    "        radius = 3 * SIGMA\n",
    "\n",
    "        # Compute edge peak points based on node sizes\n",
    "        edge_peak_points = []\n",
    "        for edge in G.edges():\n",
    "            i, j = edge\n",
    "            x_i = vertices[i]\n",
    "            x_j = vertices[j]\n",
    "            s_i = node_sizes[i]\n",
    "            s_j = node_sizes[j]\n",
    "            if s_i + s_j == 0:\n",
    "                t = 0.5  # Avoid division by zero; default to midpoint\n",
    "            else:\n",
    "                t = s_i / (s_i + s_j)\n",
    "            peak_point = (1 - t) * x_j + t * x_i\n",
    "            edge_peak_points.append(peak_point)\n",
    "        edge_peak_points = np.array(edge_peak_points)\n",
    "\n",
    "        # Build a KD-tree for efficient distance computation\n",
    "        edge_peak_tree = cKDTree(edge_peak_points)\n",
    "\n",
    "        # Compute scalar values at face centroids\n",
    "        face_centroids = mesh.triangles_center\n",
    "        scalar_values = np.zeros(len(face_centroids))\n",
    "\n",
    "        for i, centroid in enumerate(face_centroids):\n",
    "            # Find edge peak points within radius\n",
    "            indices = edge_peak_tree.query_ball_point(centroid, radius)\n",
    "            if indices:\n",
    "                distances = np.linalg.norm(edge_peak_points[indices] - centroid, axis=1)\n",
    "                # Compute Gaussian function values\n",
    "                gaussians = np.exp(- (distances ** 2) / (2 * SIGMA ** 2))\n",
    "                scalar_values[i] = np.sum(gaussians)\n",
    "            else:\n",
    "                scalar_values[i] = 0\n",
    "\n",
    "        # Normalize scalar values to range between 0 and 1\n",
    "        scalar_values_norm = (scalar_values - np.min(scalar_values)) / (np.max(scalar_values) - np.min(scalar_values) + 1e-8)\n",
    "\n",
    "        # Get the colormap\n",
    "        cmap_name = 'viridis'\n",
    "        if FLIP_COLORS:\n",
    "            cmap_name += '_r'  # Append '_r' to reverse the colormap\n",
    "        cmap = cm.get_cmap(cmap_name)\n",
    "\n",
    "        # Map scalar values to colors\n",
    "        mapped_colors = cmap(scalar_values_norm)  # RGBA colors\n",
    "\n",
    "        # Convert colors to uint8 with alpha channel\n",
    "        face_colors = (mapped_colors[:, :4] * 255).astype(np.uint8)\n",
    "\n",
    "        # Apply colors to faces\n",
    "        mesh.visual.face_colors = face_colors\n",
    "\n",
    "        # Create a scene\n",
    "        scene = trimesh.Scene()\n",
    "\n",
    "        # Add the colored mesh to the scene if SHOW_FACES is True\n",
    "        if SHOW_FACES:\n",
    "            scene.add_geometry(mesh, node_name='mesh')\n",
    "\n",
    "        # Compute the scale of the model\n",
    "        bounding_box = mesh.bounds\n",
    "        model_size = np.max(bounding_box[1] - bounding_box[0])\n",
    "\n",
    "        # Set node sizes and edge thickness based on model size and user-defined scales\n",
    "        NODE_SIZE = model_size * NODE_SIZE_SCALE\n",
    "        EDGE_THICKNESS = model_size * EDGE_THICKNESS_SCALE\n",
    "\n",
    "        # Normalize node sizes for scaling\n",
    "        normalized_node_sizes = (node_sizes - np.min(node_sizes)) / (np.max(node_sizes) - np.min(node_sizes) + 1e-8)\n",
    "        sizes = NODE_SIZE * (normalized_node_sizes + 0.5)  # Ensure nodes are not too small\n",
    "\n",
    "        # Create sphere meshes for nodes (black dots)\n",
    "        for i in range(len(vertices)):\n",
    "            position = vertices[i]\n",
    "            radius = sizes[i]\n",
    "            color = np.array([0, 0, 0, 255], dtype=np.uint8)  # Include alpha channel\n",
    "\n",
    "            # Create a sphere\n",
    "            sphere = trimesh.creation.icosphere(subdivisions=SPHERE_SUBDIVISIONS, radius=radius)\n",
    "            sphere.apply_translation(position)\n",
    "\n",
    "            # Assign color to the sphere's vertices\n",
    "            sphere.visual.vertex_colors = np.tile(color, (sphere.vertices.shape[0], 1))\n",
    "\n",
    "            # Add sphere to the scene\n",
    "            scene.add_geometry(sphere, node_name=f'sphere_{i}')\n",
    "\n",
    "        # Create cylinder meshes for edges (black lines)\n",
    "        for idx, edge in enumerate(G.edges()):\n",
    "            i, j = edge\n",
    "            start = vertices[i]\n",
    "            end = vertices[j]\n",
    "\n",
    "            # Compute vector from start to end\n",
    "            vector = end - start\n",
    "            length = np.linalg.norm(vector)\n",
    "            if length == 0:\n",
    "                continue  # Skip zero-length edges\n",
    "            direction = vector / length\n",
    "\n",
    "            # Create a cylinder\n",
    "            cylinder = trimesh.creation.cylinder(\n",
    "                radius=EDGE_THICKNESS,\n",
    "                height=length,\n",
    "                sections=CYLINDER_SECTIONS\n",
    "            )\n",
    "            # Align the cylinder with the edge vector\n",
    "            cylinder.apply_translation([0, 0, length / 2])\n",
    "            axis = [0, 0, 1]\n",
    "            rotation_matrix = trimesh.geometry.align_vectors(axis, direction)\n",
    "            cylinder.apply_transform(rotation_matrix)\n",
    "            # Move the cylinder to the start position\n",
    "            cylinder.apply_translation(start)\n",
    "\n",
    "            # Assign color to the cylinder (black)\n",
    "            color = np.array([0, 0, 0, 255], dtype=np.uint8)  # Include alpha channel\n",
    "            cylinder.visual.vertex_colors = np.tile(color, (cylinder.vertices.shape[0], 1))\n",
    "\n",
    "            # Add cylinder to the scene\n",
    "            scene.add_geometry(cylinder, node_name=f'cylinder_{idx}')\n",
    "\n",
    "        # Export the scene to GLB file\n",
    "        export_glb_name = f'{cell_name}-3dviz-forces.glb'\n",
    "        scene.export(export_glb_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106cf5c8-c87d-4601-9aa3-a1d11c4e45f6",
   "metadata": {},
   "source": [
    "## Mesh Export Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06da3a0-7173-4ed6-992c-11a1b02fa62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import trimesh\n",
    "import os\n",
    "\n",
    "# Attach to logger so trimesh messages will be printed to console\n",
    "trimesh.util.attach_to_log()\n",
    "\n",
    "def create_faces_from_adjacency(A):\n",
    "    G = nx.from_numpy_array(A)\n",
    "    triangles = []\n",
    "    for node in G.nodes():\n",
    "        neighbors = list(G.neighbors(node))\n",
    "        for i in range(len(neighbors)):\n",
    "            for j in range(i+1, len(neighbors)):\n",
    "                if G.has_edge(neighbors[i], neighbors[j]):\n",
    "                    triangles.append([node, neighbors[i], neighbors[j]])\n",
    "    return np.array(triangles)\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for idx, row in DATA_TO_USE.iterrows():\n",
    "    adj_matrix_file = row['adjmatrix']\n",
    "    centroid_file = row['volumes']\n",
    "    cell_name = os.path.basename(centroid_file).split('_')[:-1]\n",
    "    cell_name = '_'.join(cell_name)\n",
    "    print(f\"Processing {cell_name}\")\n",
    "\n",
    "    # Read the volumes file\n",
    "    df_raw = pd.read_csv(centroid_file, header=None, names=['x', 'y', 'z', 'volume'])\n",
    "    vertices = df_raw[['x', 'y', 'z']].values\n",
    "\n",
    "    # Read and process the adjacency matrix\n",
    "    A = np.genfromtxt(adj_matrix_file, delimiter=',')\n",
    "    G = nx.from_numpy_array(A)\n",
    "    print(f\"Adjacency matrix: {os.path.basename(adj_matrix_file)}, nodes: {G.number_of_nodes()}, edges: {G.number_of_edges()}\")\n",
    "\n",
    "    # Create faces from the adjacency matrix\n",
    "    faces = create_faces_from_adjacency(A)\n",
    "\n",
    "    try:\n",
    "        # Create mesh from vertices and faces\n",
    "        mesh = trimesh.Trimesh(vertices=vertices, faces=faces, process=False)\n",
    "\n",
    "        # Process the mesh\n",
    "        mesh.process()\n",
    "\n",
    "        # Export to GLB file\n",
    "        export_glb_name = f'{cell_name}-3dviz.glb'\n",
    "        mesh.export(export_glb_name)\n",
    "        print(f\"Exported {export_glb_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cell_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# After processing all cells, you can add additional analysis if needed\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c25f2-ab4b-4c41-9e26-3b6477b36334",
   "metadata": {},
   "source": [
    "## Show All Color Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f0586-2d82-456d-bb02-98964c9c4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get all colormap names\n",
    "cmap_names = cc.all_original_names()\n",
    "\n",
    "# Calculate the number of rows and columns\n",
    "n_cmaps = len(cmap_names)\n",
    "n_cols = 1\n",
    "n_rows = n_cmaps\n",
    "\n",
    "# Create a sample array for each colormap\n",
    "sample_data = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "\n",
    "# Create the plot\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(10, n_rows * 0.5))\n",
    "fig.subplots_adjust(top=0.95, bottom=0.01, left=0.2, right=0.99, hspace=0.35)\n",
    "\n",
    "# Plot each colormap\n",
    "for ax, name in zip(axes, cmap_names):\n",
    "    ax.imshow(sample_data, aspect='auto', cmap=cc.cm[name])\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(name, fontsize=8, loc='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
